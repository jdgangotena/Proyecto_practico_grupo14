# üîç Sistema de Predicci√≥n de Utilidad de Rese√±as

Sistema de Machine Learning y NLP para predecir la utilidad de rese√±as de productos usando clasificaci√≥n supervisada con LightGBM.

## üìã Descripci√≥n del Proyecto

Este proyecto construye un **Asistente de Rese√±as** que predice si una rese√±a ser√° considerada √∫til por otros usuarios, bas√°ndose en caracter√≠sticas extra√≠das del texto mediante t√©cnicas de NLP (Procesamiento de Lenguaje Natural).

### Componentes Principales

1. **Pipeline de Datos**: Carga, limpieza y preprocesamiento de rese√±as de Amazon
2. **Ingenier√≠a de Caracter√≠sticas NLP**: Extracci√≥n de caracter√≠sticas (longitud, sentimiento, estructura, etc.)
3. **Modelo de Clasificaci√≥n**: LightGBM para predecir utilidad binaria
4. **API REST**: FastAPI para servir predicciones
5. **Dashboard Interactivo**: Interfaz web para escribir rese√±as y obtener feedback en tiempo real

## üóÇÔ∏è Estructura del Proyecto

```
proyecto/
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ data_loader.py         # Carga y validaci√≥n de datos
‚îÇ   ‚îú‚îÄ‚îÄ limpieza.py            # Limpieza y c√°lculo de tasa de utilidad
‚îÇ   ‚îú‚îÄ‚îÄ nlp_features.py        # Extracci√≥n de caracter√≠sticas NLP
‚îÇ   ‚îî‚îÄ‚îÄ model_training.py      # Entrenamiento del modelo LightGBM
‚îú‚îÄ‚îÄ api_app.py                 # API FastAPI
‚îú‚îÄ‚îÄ dashboard.py               # Dashboard interactivo con Streamlit
‚îú‚îÄ‚îÄ requirements.txt           # Dependencias del proyecto
‚îú‚îÄ‚îÄ Dockerfile                 # Configuraci√≥n Docker
‚îú‚îÄ‚îÄ docker-compose.yml         # Orquestaci√≥n Docker
‚îú‚îÄ‚îÄ deploy.sh                  # Script de despliegue autom√°tico
‚îú‚îÄ‚îÄ data/                      # Datos (no incluido en repo)
‚îú‚îÄ‚îÄ models/                    # Modelos entrenados
‚îî‚îÄ‚îÄ plots/                     # Gr√°ficos generados
```

---

## üöÄ Instalaci√≥n y Ejecuci√≥n

### Opci√≥n 1: üê≥ Docker (Recomendado para Producci√≥n)

#### Pre-requisitos
- Docker instalado y corriendo
- Modelo entrenado en `models/review_helpfulness_model_latest.pkl`

#### Deploy R√°pido

```bash
# Opci√≥n A: Script autom√°tico (m√°s f√°cil)
./deploy.sh deploy

# Opci√≥n B: Docker Compose
docker-compose up -d --build
```

#### Verificar que funciona

```bash
# Health check
curl http://localhost:8000/health

# Documentaci√≥n interactiva
open http://localhost:8000/docs
```

#### Comandos √∫tiles

```bash
./deploy.sh          # Men√∫ interactivo
./deploy.sh logs     # Ver logs en tiempo real
./deploy.sh restart  # Reiniciar servicio
./deploy.sh stop     # Detener servicio
./deploy.sh health   # Verificar salud

# O con docker-compose:
docker-compose logs -f api
docker-compose restart api
docker-compose down
```

#### Caracter√≠sticas Docker

- ‚úÖ Imagen multi-stage optimizada (~700 MB)
- ‚úÖ Usuario no-root para seguridad
- ‚úÖ Health checks autom√°ticos
- ‚úÖ Auto-restart en caso de fallos
- ‚úÖ NLTK data precargada
- ‚úÖ Vol√∫menes para actualizar modelos sin rebuild

#### Actualizar modelo sin rebuild

```bash
# 1. Entrenar nuevo modelo
python scripts/model_training.py

# 2. Reiniciar contenedor (montar√° el nuevo modelo)
./deploy.sh restart
```

#### Deploy en producci√≥n con Nginx

```bash
# Usar configuraci√≥n de producci√≥n
docker-compose -f docker-compose.prod.yml up -d --build
```

Incluye:
- Nginx como reverse proxy
- Configuraci√≥n SSL/HTTPS
- Rate limiting
- Logs estructurados

---

### Opci√≥n 2: üíª Instalaci√≥n Local (Desarrollo)

#### 1. Crear entorno virtual

```bash
python -m venv venv

# Windows
venv\Scripts\activate

# Mac/Linux
source venv/bin/activate
```

#### 2. Instalar dependencias

```bash
pip install -r requirements.txt
```

#### 3. Descargar dataset

Descarga el dataset **Amazon Fine Food Reviews** desde Kaggle:
- URL: https://www.kaggle.com/snap/amazon-fine-food-reviews
- Coloca el archivo `Reviews.csv` en la carpeta `data/`

#### 4. Ejecutar pipeline de entrenamiento

```bash
cd scripts

# Paso 1: Cargar y explorar datos
python data_loader.py

# Paso 2: Limpieza y preprocesamiento
python limpieza.py

# Paso 3: Extracci√≥n de caracter√≠sticas NLP
python nlp_features.py

# Paso 4: Entrenar modelo
python model_training.py
```

#### 5. Iniciar API

```bash
# Volver a la ra√≠z del proyecto
cd ..

# Iniciar API
python api_app.py
```

La API estar√° disponible en: `http://localhost:8000`

#### 6. Iniciar Dashboard (Opcional)

```bash
# En otra terminal, con la API corriendo
python dashboard.py
```

Dashboard disponible en: `http://localhost:8050`

---

## üìä Pipeline de Datos

### Paso 1: Carga de Datos
**Script:** `scripts/data_loader.py`

- Carga el dataset de rese√±as
- Valida columnas requeridas
- Muestra estad√≠sticas b√°sicas
- Calcula tasa de utilidad promedio

### Paso 2: Limpieza y Preprocesamiento
**Script:** `scripts/limpieza.py`

- Calcula tasa de utilidad: `HelpfulnessNumerator / HelpfulnessDenominator`
- Crea etiqueta binaria `IsHelpful` (umbral: 70%)
- Limpia texto: lowercase, URLs, caracteres especiales
- Guarda: `data/amazon_reviews_prepared.csv`

### Paso 3: Extracci√≥n de Caracter√≠sticas NLP
**Script:** `scripts/nlp_features.py`

**Caracter√≠sticas extra√≠das:**

| Categor√≠a | Caracter√≠sticas |
|-----------|----------------|
| **Longitud y Estructura** | `char_count`, `word_count`, `sentence_count`, `avg_word_length`, `words_per_sentence` |
| **L√©xicas** | `exclamation_count`, `question_count`, `uppercase_word_count`, `lexical_diversity` |
| **Sentimiento** | `vader_neg`, `vader_neu`, `vader_pos`, `vader_compound`, `textblob_polarity`, `textblob_subjectivity` |
| **Adicionales** | `digit_ratio`, `review_score` |

**Salida:** `data/amazon_reviews_with_features.csv`

### Paso 4: Entrenamiento del Modelo
**Script:** `scripts/model_training.py`

- Algoritmo: **LightGBM** (Gradient Boosting)
- Split: 80/20 (train/test)
- M√©tricas: Accuracy, Precision, Recall, F1-Score, ROC-AUC
- Genera visualizaciones: ROC curve, feature importance, probability distribution
- Guarda modelo: `models/review_helpfulness_model_latest.pkl`

**Ejemplo de salida:**
```
M√©tricas de evaluaci√≥n:
  accuracy: 0.8234
  precision: 0.8156
  recall: 0.8312
  f1_score: 0.8233
  roc_auc: 0.8891
```

**Caracter√≠sticas m√°s importantes:**
1. `word_count`: Longitud de la rese√±a
2. `vader_compound`: Sentimiento general
3. `sentence_count`: Estructura del texto
4. `review_score`: Calificaci√≥n en estrellas
5. `lexical_diversity`: Variedad de vocabulario

---

## üåê API REST

### Endpoints Disponibles

#### 1. Health Check
```bash
GET http://localhost:8000/health
```

**Respuesta:**
```json
{
  "status": "healthy",
  "model_loaded": true,
  "model_path": "models/review_helpfulness_model_latest.pkl",
  "features_count": 17
}
```

#### 2. Predicci√≥n de Utilidad
```bash
POST http://localhost:8000/reviews/predict_helpfulness
Content-Type: application/json

{
  "text": "This product is amazing! It works exactly as described and the quality is excellent.",
  "score": 5
}
```

**Respuesta:**
```json
{
  "is_helpful_probability": 0.8234,
  "is_helpful": true,
  "confidence": "high",
  "features": {
    "char_count": 156,
    "word_count": 28,
    "sentence_count": 2,
    "vader_compound": 0.8915,
    "textblob_polarity": 0.75
  },
  "suggestions": [
    "¬°Excelente rese√±a! Es informativa y probablemente ser√° √∫til para otros usuarios."
  ]
}
```

#### 3. Informaci√≥n del Modelo
```bash
GET http://localhost:8000/model/info
```

Devuelve metadatos del modelo cargado, caracter√≠sticas y m√©tricas de evaluaci√≥n.

### Documentaci√≥n Interactiva

FastAPI genera documentaci√≥n autom√°tica:
- **Swagger UI**: http://localhost:8000/docs
- **ReDoc**: http://localhost:8000/redoc

### Ejemplos de uso con cURL

```bash
# Health check
curl http://localhost:8000/health

# Predicci√≥n
curl -X POST http://localhost:8000/reviews/predict_helpfulness \
  -H "Content-Type: application/json" \
  -d '{
    "text": "Great product! Highly recommend. Works perfectly and arrived on time.",
    "score": 5
  }'
```

---

## üì± Dashboard Interactivo

### Funcionalidades

1. **Editor de Rese√±as**
   - Selector de calificaci√≥n (1-5 estrellas)
   - √Årea de texto para escribir rese√±a
   - Contador de palabras y caracteres en tiempo real

2. **An√°lisis en Tiempo Real**
   - Indicador de utilidad (√ötil / Poco √ötil)
   - Gr√°fico gauge con puntuaci√≥n 0-100%
   - Nivel de confianza de la predicci√≥n

3. **Sugerencias Personalizadas**
   - Recomendaciones para mejorar la rese√±a
   - Feedback sobre longitud, sentimiento, estructura

4. **Visualizaci√≥n de Caracter√≠sticas**
   - Gr√°fico de barras con caracter√≠sticas extra√≠das
   - Valores num√©ricos de m√©tricas NLP

### Iniciar Dashboard

```bash
# Terminal 1: Iniciar API
python api_app.py

# Terminal 2: Iniciar Dashboard
python dashboard.py
```

Dashboard disponible en: `http://localhost:8050`

---

## ‚öôÔ∏è Configuraci√≥n Avanzada

### Variables de Entorno

Crea un archivo `.env` (ver `.env.example`):

```env
API_HOST=0.0.0.0
API_PORT=8000
API_WORKERS=4
API_CORS_ORIGINS=http://localhost:3000,https://tu-dominio.com
LOG_LEVEL=INFO
```

### Entrenar con Dataset Completo

Por defecto, los scripts cargan 50,000 filas. Para usar el dataset completo:

```python
# En limpieza.py
df = cargar_datos(DATA_PATH, nrows=None)  # Quitar nrows
```

### Ajustar Umbral de Utilidad

```python
# En limpieza.py
df = calcular_tasa_utilidad(df, umbral=0.6)  # Cambiar de 0.7 a 0.6
```

### Personalizar Hiperpar√°metros

```python
# En model_training.py
custom_params = {
    'num_leaves': 50,
    'learning_rate': 0.03,
    'max_depth': 10,
    'feature_fraction': 0.9,
    'bagging_fraction': 0.8
}
```

### Usar Gunicorn para Producci√≥n

```bash
# Instalar gunicorn
pip install gunicorn

# Ejecutar con m√∫ltiples workers
gunicorn api_app:app \
  --workers 4 \
  --worker-class uvicorn.workers.UvicornWorker \
  --bind 0.0.0.0:8000 \
  --timeout 60
```

---

## üêõ Troubleshooting

### Error: Modelo no encontrado

```bash
# Entrenar el modelo primero
cd scripts
python model_training.py
```

### Error: API no conecta

```bash
# Verificar que la API est√© ejecut√°ndose
curl http://localhost:8000/health

# Ver logs si usa Docker
docker-compose logs api
```

### Error: Puerto 8000 en uso

```bash
# Cambiar puerto en docker-compose.yml
ports:
  - "8001:8000"

# O al ejecutar localmente
uvicorn api_app:app --host 0.0.0.0 --port 8001
```

### Error: Datos no encontrados

Descarga el dataset de Kaggle y col√≥calo en `data/Reviews.csv`:
https://www.kaggle.com/snap/amazon-fine-food-reviews

### Error de NLTK

```python
# Descargar recursos manualmente
import nltk
nltk.download('vader_lexicon')
nltk.download('punkt')
nltk.download('stopwords')
nltk.download('wordnet')
```

### Docker: Contenedor se reinicia constantemente

```bash
# Ver logs detallados
docker-compose logs --tail=100 api

# Verificar health check
docker inspect review-api | grep -A 10 Health
```

---

## üåç Deploy en Coolify

### Pre-requisitos

- Servidor VPS (DigitalOcean, AWS, Hetzner, etc.)
- Coolify instalado en tu servidor
- Repositorio Git (GitHub, GitLab, Bitbucket, etc.)

### Instalaci√≥n de Coolify

Si a√∫n no tienes Coolify instalado en tu servidor:

```bash
# Conectar a tu servidor via SSH
ssh user@tu-servidor.com

# Instalar Coolify (requiere Ubuntu 20.04+ o Debian 11+)
curl -fsSL https://cdn.coollabs.io/coolify/install.sh | bash
```

Accede al panel de Coolify en: `http://tu-servidor.com:8000`

### Deploy Paso a Paso

#### 1. Preparar el Repositorio

```bash
# Aseg√∫rate de tener todos los cambios commiteados
git add .
git commit -m "Deploy to Coolify"
git push origin main
```

#### 2. Crear Aplicaci√≥n en Coolify

1. **Login en Coolify** (http://tu-servidor.com:8000)
2. **Crear nuevo proyecto**:
   - Click en "New Project"
   - Nombre: `review-api`
3. **Conectar repositorio Git**:
   - Click en "Add Source"
   - Selecciona tu proveedor Git (GitHub, GitLab, etc.)
   - Autoriza la conexi√≥n
   - Selecciona el repositorio

#### 3. Configurar Aplicaci√≥n

Coolify detectar√° autom√°ticamente el `Dockerfile` y configurar√°:

- ‚úÖ Build con Dockerfile
- ‚úÖ Puerto: 8000 (autom√°tico desde EXPOSE)
- ‚úÖ Health check: `/health`

**Configuraci√≥n opcional**:
- **Dominio personalizado**: Agregar tu dominio
- **Variables de entorno**: Ver `.env.example`
- **Puerto personalizado**: Si necesitas cambiar el puerto

#### 4. Variables de Entorno (Opcional)

En el panel de Coolify, agregar si es necesario:

```env
PORT=8000
API_CORS_ORIGINS=https://tu-dominio.com
LOG_LEVEL=INFO
```

#### 5. Deploy

Click en **"Deploy"** y Coolify autom√°ticamente:

1. Clonar√° el repositorio
2. Construir√° la imagen Docker
3. Iniciar√° el contenedor
4. Configurar√° SSL con Let's Encrypt (si tienes dominio)
5. Expondr√° la aplicaci√≥n

### Caracter√≠sticas de Coolify

- ‚úÖ **Self-hosted**: Tu propio servidor, control total
- ‚úÖ **Gratis y Open Source**: Sin costos de plataforma
- ‚úÖ **SSL Autom√°tico**: Let's Encrypt incluido
- ‚úÖ **Deploy Autom√°tico**: Webhook desde Git
- ‚úÖ **Docker Nativo**: Usa tu Dockerfile
- ‚úÖ **Logs en Tiempo Real**: Debugging f√°cil
- ‚úÖ **Health Checks**: Monitoreo autom√°tico
- ‚úÖ **Auto-restart**: Recuperaci√≥n autom√°tica

### Configurar Deploy Autom√°tico

Coolify puede hacer deploy autom√°tico cuando haces push:

1. En el dashboard de Coolify ‚Üí **Webhooks**
2. Copiar la URL del webhook
3. En tu repositorio GitHub:
   - Settings ‚Üí Webhooks ‚Üí Add webhook
   - Pegar la URL de Coolify
   - Seleccionar eventos: Push events
4. ¬°Listo! Cada push desplegar√° autom√°ticamente

### Verificar el Deploy

```bash
# Reemplaza con tu dominio o IP
export API_URL="https://tu-dominio.com"

# Health check
curl $API_URL/health

# Documentaci√≥n
open $API_URL/docs

# Hacer predicci√≥n
curl -X POST $API_URL/reviews/predict_helpfulness \
  -H "Content-Type: application/json" \
  -d '{
    "text": "Amazing product! Highly recommend.",
    "score": 5
  }'
```

### Logs y Debugging

En el dashboard de Coolify:
- **Logs**: Ver logs en tiempo real
- **Build Logs**: Revisar el proceso de build
- **Restart**: Reiniciar la aplicaci√≥n
- **Rebuild**: Reconstruir desde cero

### Actualizar el Modelo

```bash
# 1. Entrenar nuevo modelo localmente
python scripts/model_training.py

# 2. Commitear y push
git add models/
git commit -m "Update model"
git push origin main

# 3. Coolify redesplegar√° autom√°ticamente (si webhook configurado)
# O hacer rebuild manual desde el dashboard
```

### Mejores Pr√°cticas para Producci√≥n

1. **Seguridad**
   - Usuario no-root en contenedor ‚úÖ
   - HTTPS/SSL con certificados v√°lidos
   - Variables de entorno para secrets
   - Rate limiting en endpoints

2. **Performance**
   - Usar Gunicorn con m√∫ltiples workers
   - Configurar timeouts apropiados
   - Implementar cach√© para predicciones frecuentes
   - Monitoreo con Prometheus/Grafana

3. **Mantenibilidad**
   - CI/CD con GitHub Actions
   - Versionado de im√°genes Docker
   - Logs estructurados (JSON)
   - Backups autom√°ticos de modelos

---

## üìä Resultados Esperados

Con el dataset completo (568,454 rese√±as):

- **ROC-AUC**: ~0.88-0.91
- **Accuracy**: ~0.82-0.85
- **F1-Score**: ~0.81-0.84

---

## üìö Recursos

- **Dataset**: [Amazon Fine Food Reviews (Kaggle)](https://www.kaggle.com/snap/amazon-fine-food-reviews)
- **LightGBM**: [Documentaci√≥n oficial](https://lightgbm.readthedocs.io/)
- **FastAPI**: [Documentaci√≥n oficial](https://fastapi.tiangolo.com/)
- **Streamlit**: [Documentaci√≥n oficial](https://docs.streamlit.io/)
- **NLTK**: [Natural Language Toolkit](https://www.nltk.org/)
- **Docker**: [Documentaci√≥n oficial](https://docs.docker.com/)

---

## ü§ù Contribuciones

Este proyecto es parte de un ejercicio acad√©mico de Machine Learning y NLP.

## üìù Licencia

MIT License - Libre para uso educativo y personal.

## üë• Autores

Proyecto desarrollado como caso de estudio de Aprendizaje Supervisado y NLP.

---

## üéØ Quick Start

```bash
# 1. Clonar repo y navegar
cd Proyecto_practico_grupo14

# 2. Deploy con Docker (opci√≥n m√°s r√°pida)
./deploy.sh deploy

# 3. Probar API
curl http://localhost:8000/health
open http://localhost:8000/docs

# 4. Hacer predicci√≥n
curl -X POST http://localhost:8000/reviews/predict_helpfulness \
  -H "Content-Type: application/json" \
  -d '{"text": "Amazing product!", "score": 5}'
```

**¬øPreguntas?** Consulta la documentaci√≥n interactiva en http://localhost:8000/docs
