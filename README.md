# ğŸ” Sistema de PredicciÃ³n de Utilidad de ReseÃ±as

Sistema de Machine Learning y NLP para predecir la utilidad de reseÃ±as de productos usando clasificaciÃ³n supervisada con LightGBM.

## ğŸ“‹ DescripciÃ³n del Proyecto

Este proyecto construye un **Asistente de ReseÃ±as** que predice si una reseÃ±a serÃ¡ considerada Ãºtil por otros usuarios, basÃ¡ndose en caracterÃ­sticas extraÃ­das del texto mediante tÃ©cnicas de NLP (Procesamiento de Lenguaje Natural).

### Componentes Principales

1. **Pipeline de Datos**: Carga, limpieza y preprocesamiento de reseÃ±as de Amazon
2. **IngenierÃ­a de CaracterÃ­sticas NLP**: ExtracciÃ³n de caracterÃ­sticas (longitud, sentimiento, estructura, etc.)
3. **Modelo de ClasificaciÃ³n**: LightGBM para predecir utilidad binaria
4. **API REST**: FastAPI para servir predicciones
5. **Dashboard Interactivo**: Interfaz web para escribir reseÃ±as y obtener feedback en tiempo real

## ğŸ¯ Objetivo

Predecir la "puntuaciÃ³n de utilidad" de una reseÃ±a calculando caracterÃ­sticas de calidad del texto y entrenando un modelo que aprenda la relaciÃ³n entre estas caracterÃ­sticas y la utilidad percibida por usuarios.

## ğŸ—‚ï¸ Estructura del Proyecto por carpetas

```
opiniones_ecommners-1/
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ data_loader.py         # Carga y validaciÃ³n de datos
â”‚   â”œâ”€â”€ limpieza.py            # Limpieza y cÃ¡lculo de tasa de utilidad
â”‚   â”œâ”€â”€ nlp_features.py        # ExtracciÃ³n de caracterÃ­sticas NLP
â”‚   â””â”€â”€ model_training.py      # Entrenamiento del modelo LightGBM
â”œâ”€â”€ api_app.py                 # API FastAPI
â”œâ”€â”€ dashboard.py               # Dashboard interactivo con Dash
â”œâ”€â”€ requirements.txt           # Dependencias del proyecto
â”œâ”€â”€ data/                      # Datos (no incluido en repo)
â”‚   â”œâ”€â”€ Reviews.csv
â”‚   â”œâ”€â”€ amazon_reviews_prepared.csv
â”‚   â””â”€â”€ amazon_reviews_with_features.csv
â”œâ”€â”€ models/                    # Modelos entrenados
â”‚   â””â”€â”€ review_helpfulness_model_latest.pkl
â””â”€â”€ plots/                     # GrÃ¡ficos generados
    â”œâ”€â”€ roc_curve.html
    â”œâ”€â”€ feature_importance.html
    â””â”€â”€ probability_distribution.html
```

## ğŸš€ InstalaciÃ³n

### 1. Clonar el repositorio

```bash
cd opiniones_ecommners-1
```

### 2. Crear entorno virtual

```bash
python -m venv venv

# Windows
venv\Scripts\activate

# Mac/Linux
source venv/bin/activate
```

### 3. Instalar dependencias requirements

```bash
pip install -r requirements.txt
```

### 4. Descargar dataset

Descarga el dataset **Amazon Fine Food Reviews** desde Kaggle:
- URL: https://www.kaggle.com/snap/amazon-fine-food-reviews
- Coloca el archivo `Reviews.csv` en la carpeta `data/`

## ğŸ“Š Pipeline de EjecuciÃ³n

### Paso 1: Cargar y Explorar Datos

```bash
cd scripts
python data_loader.py
```

**Funcionalidades:**
- Carga el dataset de reseÃ±as
- Valida columnas requeridas
- Muestra estadÃ­sticas bÃ¡sicas
- Calcula tasa de utilidad promedio

### Paso 2: Limpieza y Preprocesamiento

```bash
python limpieza.py
```

**Funcionalidades:**
- Calcula tasa de utilidad: `HelpfulnessNumerator / HelpfulnessDenominator`
- Crea etiqueta binaria `IsHelpful` (umbral: 70%)
- Limpia texto: lowercase, URLs, caracteres especiales
- Guarda dataset preparado: `data/amazon_reviews_prepared.csv`

### Paso 3: ExtracciÃ³n de CaracterÃ­sticas NLP

```bash
python nlp_features.py
```

**CaracterÃ­sticas ExtraÃ­das:**

**Longitud y Estructura:**
- `char_count`: NÃºmero de caracteres
- `word_count`: NÃºmero de palabras
- `sentence_count`: NÃºmero de oraciones
- `avg_word_length`: Longitud promedio de palabras
- `words_per_sentence`: Palabras por oraciÃ³n

**LÃ©xicas:**
- `exclamation_count`: Exclamaciones
- `question_count`: Preguntas
- `uppercase_word_count`: Palabras en mayÃºsculas
- `lexical_diversity`: Type-token ratio

**Sentimiento:**
- `vader_neg`, `vader_neu`, `vader_pos`, `vader_compound`: Sentimiento VADER
- `textblob_polarity`: Polaridad (-1 a 1)
- `textblob_subjectivity`: Subjetividad (0 a 1)

**Adicionales:**
- `digit_ratio`: ProporciÃ³n de dÃ­gitos
- `review_score`: CalificaciÃ³n en estrellas

**Salida:** `data/amazon_reviews_with_features.csv`

### Paso 4: Entrenar Modelo

```bash
python model_training.py
```

**Funcionalidades:**
- Entrena modelo LightGBM con caracterÃ­sticas NLP
- Split train/test: 80/20
- MÃ©tricas: Accuracy, Precision, Recall, F1-Score, ROC-AUC
- Genera grÃ¡ficos con Plotly:
  - Curva ROC
  - Importancia de caracterÃ­sticas
  - DistribuciÃ³n de probabilidades
- Guarda modelo: `models/review_helpfulness_model_latest.pkl`

**Ejemplo de Salida:**
```
MÃ©tricas de evaluaciÃ³n:
  accuracy: 0.8234
  precision: 0.8156
  recall: 0.8312
  f1_score: 0.8233
  roc_auc: 0.8891
```

## ğŸŒ API REST con FastAPI

### Iniciar API

```bash
python api_app.py
```

La API estarÃ¡ disponible en: `http://localhost:8000`

### Endpoints

#### 1. Health Check

```bash
GET http://localhost:8000/health
```

**Respuesta:**
```json
{
  "status": "healthy",
  "model_loaded": true,
  "model_path": "models/review_helpfulness_model_latest.pkl",
  "features_count": 17
}
```

#### 2. PredicciÃ³n de Utilidad

```bash
POST http://localhost:8000/reviews/predict_helpfulness
```

**Request Body:**
```json
{
  "text": "This product is amazing! It works exactly as described and the quality is excellent. I highly recommend it to anyone looking for a reliable solution.",
  "score": 5
}
```

**Respuesta:**
```json
{
  "is_helpful_probability": 0.8234,
  "is_helpful": true,
  "confidence": "high",
  "features": {
    "char_count": 156,
    "word_count": 28,
    "sentence_count": 2,
    "vader_compound": 0.8915,
    "textblob_polarity": 0.75,
    ...
  },
  "suggestions": [
    "Â¡Excelente reseÃ±a! Es informativa y probablemente serÃ¡ Ãºtil para otros usuarios."
  ]
}
```

#### 3. InformaciÃ³n del Modelo

```bash
GET http://localhost:8000/model/info
```

### DocumentaciÃ³n Interactiva

FastAPI genera documentaciÃ³n automÃ¡tica:
- Swagger UI: http://localhost:8000/docs
- ReDoc: http://localhost:8000/redoc

## ğŸ“± Dashboard Interactivo

### Iniciar Dashboard

**Importante:** La API debe estar ejecutÃ¡ndose primero.

```bash
# Terminal 1: Iniciar API
python api_app.py

# Terminal 2: Iniciar Dashboard
python dashboard.py
```

Dashboard disponible en: `http://localhost:8050`

### Funcionalidades del Dashboard

1. **Editor de ReseÃ±as:**
   - Selector de calificaciÃ³n (1-5 estrellas)
   - Ãrea de texto para escribir reseÃ±a
   - Contador de palabras y caracteres en tiempo real

2. **AnÃ¡lisis en Tiempo Real:**
   - Indicador de utilidad (Ãštil / Poco Ãštil)
   - GrÃ¡fico gauge con puntuaciÃ³n 0-100%
   - Nivel de confianza de la predicciÃ³n

3. **Sugerencias Personalizadas:**
   - Recomendaciones para mejorar la reseÃ±a
   - Feedback sobre longitud, sentimiento, estructura

4. **VisualizaciÃ³n de CaracterÃ­sticas:**
   - GrÃ¡fico de barras con caracterÃ­sticas extraÃ­das
   - Valores numÃ©ricos de mÃ©tricas NLP

## ğŸ“ˆ CaracterÃ­sticas del Modelo

### Algoritmo

- **LightGBM** (Gradient Boosting)
  - RÃ¡pido y eficiente
  - Maneja bien features numÃ©ricas
  - Reduce overfitting con regularizaciÃ³n

### HiperparÃ¡metros

```python
{
    'objective': 'binary',
    'metric': 'binary_logloss',
    'num_leaves': 31,
    'learning_rate': 0.05,
    'feature_fraction': 0.9,
    'bagging_fraction': 0.8
}
```

### MÃ©tricas de EvaluaciÃ³n

- **Accuracy**: Porcentaje de predicciones correctas
- **Precision**: ProporciÃ³n de predicciones positivas correctas
- **Recall**: ProporciÃ³n de casos positivos detectados
- **F1-Score**: Media armÃ³nica de precision y recall
- **ROC-AUC**: Ãrea bajo la curva ROC

## ğŸ”§ Uso Avanzado

### Entrenar con Dataset Completo

Por defecto, los scripts cargan 50,000 filas para pruebas rÃ¡pidas. Para entrenar con todo el dataset:

```python
# En limpieza.py, lÃ­nea 211
df = cargar_datos(DATA_PATH, nrows=None)  # Quitar nrows

# O desde lÃ­nea de comandos
python limpieza.py --full-dataset
```

### Ajustar Umbral de Utilidad

```python
# En limpieza.py, lÃ­nea 218
df = calcular_tasa_utilidad(df, umbral=0.6)  # Cambiar umbral
```

### Personalizar Modelo

```python
# En model_training.py
custom_params = {
    'num_leaves': 50,
    'learning_rate': 0.03,
    'max_depth': 10
}
model.entrenar(X_train, y_train, params=custom_params)
```

## ğŸ“Š Resultados Esperados

Con el dataset completo (568,454 reseÃ±as), se esperan resultados similares a:

- **ROC-AUC**: ~0.88-0.91
- **Accuracy**: ~0.82-0.85
- **F1-Score**: ~0.81-0.84

### CaracterÃ­sticas MÃ¡s Importantes

TÃ­picamente, las caracterÃ­sticas mÃ¡s predictivas son:
1. `word_count`: Longitud de la reseÃ±a
2. `vader_compound`: Sentimiento general
3. `sentence_count`: Estructura del texto
4. `review_score`: CalificaciÃ³n en estrellas
5. `lexical_diversity`: Variedad de vocabulario

## ğŸ› Troubleshooting

### Error: Modelo no encontrado

```bash
# Entrenar el modelo primero
cd scripts
python model_training.py
```

### Error: API no conecta

```bash
# Verificar que la API estÃ© ejecutÃ¡ndose
curl http://localhost:8000/health
```

### Error: Datos no encontrados

```bash
# Descargar dataset de Kaggle
# Colocar Reviews.csv en carpeta data/
```

### Error de NLTK

```python
# Descargar recursos manualmente
import nltk
nltk.download('vader_lexicon')
nltk.download('punkt')
nltk.download('stopwords')
nltk.download('wordnet')
```

## ğŸ“š Recursos

- **Dataset**: [Amazon Fine Food Reviews (Kaggle)](https://www.kaggle.com/snap/amazon-fine-food-reviews)
- **LightGBM**: [DocumentaciÃ³n oficial](https://lightgbm.readthedocs.io/)
- **FastAPI**: [DocumentaciÃ³n oficial](https://fastapi.tiangolo.com/)
- **Dash**: [DocumentaciÃ³n oficial](https://dash.plotly.com/)
- **NLTK**: [Natural Language Toolkit](https://www.nltk.org/)

## ğŸ¤ Contribuciones

Este proyecto es parte de un ejercicio acadÃ©mico de Machine Learning y NLP.

## ğŸ“ Licencia

MIT License - Libre para uso educativo y personal.

## ğŸ‘¥ Autores

Proyecto desarrollado como caso de estudio de Aprendizaje Supervisado y NLP.

---

**Â¿Preguntas?** Consulta la documentaciÃ³n interactiva de la API en http://localhost:8000/docs
