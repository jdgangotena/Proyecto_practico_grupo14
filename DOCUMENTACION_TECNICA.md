# üìö Documentaci√≥n T√©cnica - Sistema de Predicci√≥n de Utilidad de Rese√±as

## üìå Resumen Ejecutivo

Sistema de Machine Learning para predecir la utilidad de rese√±as de productos bas√°ndose **exclusivamente en caracter√≠sticas objetivas del texto**. El modelo eval√∫a la calidad informativa del contenido sin sesgo hacia rese√±as positivas o negativas.

---

## üéØ Filosof√≠a del Sistema

El sistema est√° dise√±ado para valorar **rese√±as informativas y detalladas**, independientemente de si son positivas o negativas. Una rese√±a √∫til es aquella que proporciona informaci√≥n valiosa para otros compradores.

### Principios Fundamentales

1. **Objetividad**: El modelo juzga solo por contenido informativo, no por sentimiento
2. **Independencia de calificaci√≥n**: Una rese√±a de 1 estrella puede ser tan √∫til como una de 5 estrellas
3. **Valoraci√≥n de detalles**: Rese√±as con informaci√≥n espec√≠fica son consideradas m√°s √∫tiles

---

## üî¨ Caracter√≠sticas Extra√≠das (14 Features)

El modelo utiliza **14 caracter√≠sticas objetivas** divididas en 4 categor√≠as:

### 1. Caracter√≠sticas de Longitud (5 features)

Miden la extensi√≥n y estructura del texto:

| Feature | Descripci√≥n | Ejemplo |
|---------|-------------|---------|
| `char_count` | N√∫mero total de caracteres | 1250 |
| `word_count` | N√∫mero total de palabras | 237 |
| `avg_word_length` | Longitud promedio de palabras | 5.2 |
| `sentence_count` | N√∫mero de oraciones | 12 |
| `words_per_sentence` | Palabras por oraci√≥n (promedio) | 19.75 |

**Justificaci√≥n**: Rese√±as m√°s largas y bien estructuradas tienden a proporcionar m√°s informaci√≥n.

### 2. Caracter√≠sticas L√©xicas (4 features)

Analizan la riqueza del vocabulario y √©nfasis:

| Feature | Descripci√≥n | Ejemplo |
|---------|-------------|---------|
| `exclamation_count` | N√∫mero de signos de exclamaci√≥n | 3 |
| `question_count` | N√∫mero de signos de interrogaci√≥n | 1 |
| `uppercase_word_count` | Palabras en may√∫sculas (√©nfasis) | 2 |
| `lexical_diversity` | Ratio de palabras √∫nicas / total | 0.68 |

**Justificaci√≥n**: Alta diversidad l√©xica indica vocabulario rico y descripci√≥n detallada.

### 3. Caracter√≠sticas B√°sicas (1 feature)

| Feature | Descripci√≥n | Ejemplo |
|---------|-------------|---------|
| `digit_ratio` | Proporci√≥n de d√≠gitos en el texto | 0.042 |

**Justificaci√≥n**: Menciones de n√∫meros indican datos espec√≠ficos (precios, medidas, tiempos, etc.).

### 4. Caracter√≠sticas Espec√≠ficas del Dominio - Amazon Food Reviews (4 features)

Detectan vocabulario y patrones espec√≠ficos de rese√±as de alimentos:

| Feature | Descripci√≥n | Ejemplo |
|---------|-------------|---------|
| `specificity_score` | Menciones de sabor, textura y calidad | 5 |
| `has_comparison` | Comparaci√≥n con otros productos (0/1) | 1 |
| `personal_experience_score` | Pronombres personales + indicadores de tiempo | 8 |
| `price_mention` | Menciona precio/valor (0/1) | 1 |

**Justificaci√≥n**:
- **Especificidad**: Vocabulario t√©cnico de alimentos (sweet, salty, crunchy, fresh) indica experiencia real
- **Comparaciones**: "Better than Brand X" ayuda a tomar decisiones de compra
- **Experiencia personal**: "I've been using for months" indica uso genuino del producto
- **Precio**: Menciones de valor/precio son √∫tiles para compradores

---

## üö´ Caracter√≠sticas Excluidas Intencionalmente

Las siguientes caracter√≠sticas **NO** se utilizan para evitar sesgos:

### ‚ùå Caracter√≠sticas de Sentimiento

- **VADER** (vader_compound, vader_pos, vader_neg, vader_neu)
- **TextBlob** (textblob_polarity, textblob_subjectivity)

**Raz√≥n**: Estas caracter√≠sticas crean sesgo contra rese√±as negativas detalladas. Una rese√±a muy negativa pero informativa es tan √∫til como una positiva informativa.

### ‚ùå Calificaci√≥n del Producto

- **review_score** (1-5 estrellas)

**Raz√≥n**: La calificaci√≥n no indica utilidad del texto. Una rese√±a de 1 estrella bien justificada es m√°s √∫til que una de 5 estrellas que solo dice "excelente".

---

## üß† Arquitectura del Modelo

### Algoritmo: LightGBM (Gradient Boosting)

**Configuraci√≥n del modelo:**

```python
params = {
    'objective': 'binary',           # Clasificaci√≥n binaria
    'metric': 'binary_logloss',      # M√©trica de optimizaci√≥n
    'num_leaves': 31,                # Complejidad del √°rbol
    'learning_rate': 0.05,           # Tasa de aprendizaje
    'feature_fraction': 0.9,         # Fracci√≥n de features por √°rbol
    'bagging_fraction': 0.8,         # Fracci√≥n de datos por √°rbol
    'bagging_freq': 5,               # Frecuencia de bagging
    'verbose': -1                    # Sin output detallado
}
```

### Divisi√≥n de Datos

- **Train**: 80% (stratified)
- **Test**: 20% (stratified)
- **Estratificaci√≥n**: Mantiene proporci√≥n de clases √∫til/no √∫til

---

## üìä Definici√≥n de Utilidad

### C√°lculo de Tasa de Utilidad

```python
HelpfulnessRate = HelpfulnessNumerator / HelpfulnessDenominator
```

- **HelpfulnessNumerator**: Votos de "√∫til"
- **HelpfulnessDenominator**: Total de votos

### Etiqueta Binaria

```python
IsHelpful = 1 if HelpfulnessRate >= 0.70 else 0
```

- **√ötil (1)**: ‚â• 70% de votos positivos
- **No √∫til (0)**: < 70% de votos positivos
- **Filtro**: Solo rese√±as con al menos 1 voto

---

## üîÑ Pipeline de Procesamiento

### 1. Carga de Datos (`data_loader.py`)

```bash
python scripts/data_loader.py
```

**Entrada**: `data/Reviews.csv` (dataset de Amazon)

**Salida**: DataFrame validado con estad√≠sticas

**Funciones principales:**
- `cargar_datos()`: Carga CSV
- `validar_columnas()`: Verifica columnas requeridas
- `obtener_estadisticas_basicas()`: Calcula m√©tricas del dataset

### 2. Limpieza (`limpieza.py`)

```bash
python scripts/limpieza.py
```

**Entrada**: Dataset crudo

**Salida**: `data/amazon_reviews_prepared.csv`

**Funciones principales:**
- `limpiar_texto()`: Normaliza texto, elimina HTML
- `calcular_tasa_utilidad()`: Calcula HelpfulnessRate e IsHelpful

### 3. Extracci√≥n de Features (`nlp_features.py`)

```bash
python scripts/nlp_features.py
```

**Entrada**: `data/amazon_reviews_prepared.csv`

**Salida**: `data/amazon_reviews_with_features.csv`

**Clase principal**: `NLPFeatureExtractor`

**M√©todos:**
- `extraer_longitud_texto()`: 5 features de longitud
- `extraer_caracteristicas_lexicas()`: 4 features l√©xicas
- `extraer_caracteristicas_adicionales()`: 1 feature adicional
- `extraer_todas_caracteristicas()`: Combina todas las features

### 4. Entrenamiento del Modelo (`model_training.py`)

```bash
python scripts/model_training.py
```

**Entrada**: `data/amazon_reviews_with_features.csv`

**Salida**:
- `models/review_helpfulness_model_latest.pkl`
- `plots/roc_curve.html`
- `plots/feature_importance.html`
- `plots/probability_distribution.html`

**Clase principal**: `ReviewHelpfulnessModel`

**M√©todos:**
- `preparar_datos()`: Split train/test
- `entrenar()`: Entrena LightGBM
- `evaluar()`: Calcula m√©tricas de rendimiento
- `guardar()`: Serializa modelo con pickle

---

## üåê API REST (FastAPI)

### Iniciar API

```bash
python api_app.py
```

**URL**: http://localhost:8000

**Documentaci√≥n interactiva**: http://localhost:8000/docs

### Endpoints

#### 1. Health Check

```http
GET /health
```

**Respuesta:**
```json
{
  "status": "healthy",
  "model_loaded": true,
  "features_count": 10
}
```

#### 2. Predicci√≥n de Utilidad

```http
POST /reviews/predict_helpfulness
```

**Request Body:**
```json
{
  "text": "This product is excellent! The quality is outstanding...",
  "score": 5
}
```

**Response:**
```json
{
  "is_helpful": true,
  "is_helpful_probability": 0.856,
  "confidence": "high",
  "features": {
    "char_count": 1250,
    "word_count": 237,
    "sentence_count": 12,
    "lexical_diversity": 0.68,
    ...
  },
  "suggestions": [
    "Excelente nivel de detalle en tu rese√±a.",
    "Tu rese√±a tiene una estructura clara con m√∫ltiples oraciones."
  ]
}
```

### Niveles de Confianza

| Probabilidad | Nivel | Color |
|--------------|-------|-------|
| ‚â• 70% | high | üü¢ Verde |
| 50-70% | medium | üü° Amarillo |
| < 50% | low | üî¥ Rojo |

### Sistema de Sugerencias

La API proporciona feedback personalizado:

- **Longitud insuficiente**: "Tu rese√±a es muy corta. A√±ade m√°s detalles..."
- **Falta de estructura**: "Considera organizar tu rese√±a en p√°rrafos..."
- **Falta de datos**: "Incluye informaci√≥n espec√≠fica como precios, medidas..."
- **Buena calidad**: "Excelente nivel de detalle en tu rese√±a."

---

## üñ•Ô∏è Dashboard Interactivo (Streamlit)

### Iniciar Dashboard

```bash
streamlit run dashboard.py
```

**URL**: http://localhost:8501

### Caracter√≠sticas del Dashboard

1. **Entrada de Rese√±a**
   - √Årea de texto para escribir rese√±a
   - Selector de calificaci√≥n (1-5 estrellas)
   - Contador de palabras y caracteres

2. **Resultados de An√°lisis**
   - Gauge visual de utilidad (0-100%)
   - Nivel de confianza
   - Sugerencias personalizadas
   - Gr√°fico de caracter√≠sticas extra√≠das

3. **Sidebar**
   - Estado de conexi√≥n con API
   - Informaci√≥n del modelo
   - Ejemplos pre-cargados

---

## üìà M√©tricas de Rendimiento

### M√©tricas de Clasificaci√≥n

El modelo es evaluado con las siguientes m√©tricas:

- **Accuracy**: Precisi√≥n general
- **Precision**: Proporci√≥n de predicciones positivas correctas
- **Recall**: Proporci√≥n de casos positivos detectados
- **F1-Score**: Media arm√≥nica de precision y recall
- **ROC-AUC**: √Årea bajo la curva ROC

### Visualizaciones Generadas

1. **ROC Curve** (`plots/roc_curve.html`)
   - Curva ROC con √°rea bajo la curva
   - Punto √≥ptimo de threshold

2. **Feature Importance** (`plots/feature_importance.html`)
   - Importancia relativa de cada caracter√≠stica
   - Ordenadas de mayor a menor impacto

3. **Probability Distribution** (`plots/probability_distribution.html`)
   - Distribuci√≥n de probabilidades predichas
   - Separaci√≥n entre clases

---

## üîß Configuraci√≥n Avanzada

### Ajustar Umbral de Utilidad

En `scripts/limpieza.py`:

```python
def calcular_tasa_utilidad(df, umbral=0.7):  # Cambiar 0.7 a otro valor
    ...
```

**Valores sugeridos:**
- `0.6`: M√°s permisivo (m√°s rese√±as marcadas como √∫tiles)
- `0.7`: Est√°ndar (usado actualmente)
- `0.8`: M√°s estricto (solo rese√±as muy valoradas)

### Modificar Hiperpar√°metros del Modelo

En `scripts/model_training.py`:

```python
default_params = {
    'num_leaves': 31,        # ‚Üë Mayor complejidad, ‚Üì Menor complejidad
    'learning_rate': 0.05,   # ‚Üë Aprendizaje m√°s r√°pido, ‚Üì M√°s lento
    'num_boost_round': 200   # ‚Üë M√°s iteraciones, ‚Üì Menos iteraciones
}
```

### Usar Todo el Dataset

Por defecto se procesan 50,000 filas. Para usar todo el dataset:

```bash
python run_pipeline.py --nrows 0
```

**Advertencia**: Esto puede tomar 30-60 minutos.

---

## üêõ Troubleshooting

### Problema: "Modelo no encontrado"

**Soluci√≥n:**
```bash
python run_pipeline.py
```

### Problema: "API no conecta"

**Soluci√≥n:**
```bash
# Verificar que la API est√© corriendo
curl http://localhost:8000/health

# Si no est√° corriendo, iniciarla
python api_app.py
```

### Problema: "Dataset no encontrado"

**Soluci√≥n:**
1. Descargar `Reviews.csv` de Kaggle
2. Colocar en carpeta `data/`

### Problema: Error de NLTK

**Soluci√≥n:**
```python
import nltk
nltk.download('punkt')
nltk.download('punkt_tab')
```

---

## üì¶ Dependencias Principales

```
# Machine Learning
pandas>=2.0.0
numpy>=1.24.0
scikit-learn>=1.3.0
lightgbm>=4.0.0

# NLP (solo para procesamiento b√°sico)
nltk>=3.8.0

# API
fastapi>=0.100.0
uvicorn[standard]>=0.23.0
pydantic>=2.0.0

# Dashboard
streamlit>=1.39.0

# Visualizaci√≥n
plotly>=5.14.0
```

**Nota**: VADER y TextBlob est√°n instalados pero no se utilizan en el modelo.

---

## üéì Casos de Uso

### Caso 1: Rese√±a Negativa Detallada

**Entrada:**
```
"I purchased this product for work but it was very disappointing.
The packaging arrived damaged without protective padding. The
materials are low-quality plastic that scratches easily. After 4
days the switch began to fail. The battery lasts only 55 minutes
instead of the advertised 4 hours. Customer support was non-existent."
```

**Resultado esperado**: 70-85% √∫til

**Raz√≥n**: Alto word_count, m√∫ltiples sentence_count, datos espec√≠ficos (digit_ratio), buena estructura.

### Caso 2: Rese√±a Positiva Corta

**Entrada:**
```
"Excellent product!"
```

**Resultado esperado**: 20-30% √∫til

**Raz√≥n**: Bajo word_count, baja lexical_diversity, sin detalles espec√≠ficos.

### Caso 3: Rese√±a Balanceada

**Entrada:**
```
"The product works well for basic tasks. Build quality is decent
but not premium. Battery life is average (about 3-4 hours). Good
value for the price. Some features are missing compared to
competitors."
```

**Resultado esperado**: 60-75% √∫til

**Raz√≥n**: Detalles espec√≠ficos, estructura clara, informaci√≥n balanceada.

---

## üîÑ Flujo Completo de Uso

### 1. Primera Instalaci√≥n

```bash
# Instalar dependencias
pip install -r requirements.txt

# Descargar dataset
# (Manual desde Kaggle)

# Ejecutar pipeline completo
python run_pipeline.py
```

### 2. Uso Diario

**Terminal 1 - API:**
```bash
python api_app.py
```

**Terminal 2 - Dashboard:**
```bash
streamlit run dashboard.py
```

**Navegador:**
- Abrir http://localhost:8501
- Escribir rese√±a
- Obtener predicci√≥n en tiempo real

---

## üìä Interpretaci√≥n de Resultados

### Probabilidad de Utilidad

| Rango | Interpretaci√≥n |
|-------|----------------|
| 0-30% | Rese√±a poco informativa (muy corta o gen√©rica) |
| 30-50% | Rese√±a moderadamente √∫til (falta detalle o estructura) |
| 50-70% | Rese√±a √∫til (buena longitud y algunos detalles) |
| 70-100% | Rese√±a muy √∫til (detallada, estructurada, informativa) |

### Caracter√≠sticas Importantes

Las features con mayor impacto t√≠picamente son:

1. **word_count**: Rese√±as m√°s largas tienden a ser m√°s √∫tiles
2. **lexical_diversity**: Vocabulario rico indica descripci√≥n detallada
3. **sentence_count**: Estructura en m√∫ltiples oraciones
4. **digit_ratio**: Presencia de datos num√©ricos espec√≠ficos

---

## üöÄ Mejoras Futuras Sugeridas

1. **Soporte Multiling√ºe**: Agregar an√°lisis para espa√±ol y otros idiomas
2. **Detecci√≥n de T√≥picos**: Identificar temas mencionados (calidad, precio, durabilidad)
3. **An√°lisis de Comparaciones**: Detectar menciones de productos competidores
4. **Features Sem√°nticas**: Usar embeddings (BERT, GPT) para capturar significado
5. **Feedback Loop**: Aprender de las valoraciones de usuarios del dashboard

---

## üìÑ Licencia y Uso

Este sistema est√° dise√±ado para uso educativo y de investigaci√≥n. El dataset Amazon Fine Food Reviews est√° sujeto a la licencia de Kaggle.

---

## üë• Soporte

Para preguntas o problemas:
1. Revisar esta documentaci√≥n
2. Ejecutar `python check_setup.py` para verificar instalaci√≥n
3. Consultar logs de la API y dashboard para errores espec√≠ficos

---

**√öltima actualizaci√≥n**: 2025-11-07
